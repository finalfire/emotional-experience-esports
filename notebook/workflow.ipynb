{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pymongo import MongoClient\n",
    "from sklearn.preprocessing import normalize\n",
    "from wasabi import msg\n",
    "import datetime\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import powerlaw\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here data from the .csv should be processed\n",
    "# The suggested library for managing the data is pandas\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive analysis\n",
    "\n",
    "1. Distribution of comments (per len, per score, per no. of authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = list(map(lambda b: len(str(b)), comments_df.body))\n",
    "k = Counter(dist)\n",
    "\n",
    "pl = powerlaw.Fit(dist, discrete=True, verbose=False)\n",
    "print(f'alpha = {pl.alpha}')\n",
    "print(f'∂ = {pl.D}')\n",
    "\n",
    "msg.info(\"No. of comments having length n:\")\n",
    "msg.info(f\"min: {min(dist)}, avg: {np.mean(dist)}, max: {max(dist)}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "sns.scatterplot(x=list(k.keys()), y=[k[x] for x in k.keys()], ax=ax, linewidth=0., alpha=.75);\n",
    "\n",
    "ax.set_ylabel('No. of comments', **{'fontsize': 14})\n",
    "ax.set_xlabel('Comment length', **{'fontsize': 14})\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = comments_df.score.values\n",
    "k = Counter(dist)\n",
    "\n",
    "print('negative score')\n",
    "pl = powerlaw.Fit(dist[dist < 0]*-1, discrete=True, verbose=False)\n",
    "print(f'alpha = {pl.alpha}')\n",
    "print(f'∂ = {pl.D}')\n",
    "\n",
    "print('positive score')\n",
    "pl = powerlaw.Fit(dist[dist > 0], discrete=True, verbose=False)\n",
    "print(f'alpha = {pl.alpha}')\n",
    "print(f'∂ = {pl.D}')\n",
    "\n",
    "msg.info(\"No. of comments having score s:\")\n",
    "msg.info(f\"min: {min(dist)}, avg: {np.mean(dist)}, max: {max(dist)}\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, gridspec_kw={'width_ratios': [2, 4]}, figsize=(8,5))\n",
    "\n",
    "pos_x = list(filter(lambda x: x > 0, k.keys()))\n",
    "pos_y = [k[x] for x in pos_x]\n",
    "neg_x = list(filter(lambda x: x <= 0, k.keys()))\n",
    "neg_y = [k[x] for x in neg_x]\n",
    "\n",
    "sns.scatterplot(x=pos_x, y=pos_y, linewidth=0., alpha=.75, ax=ax[1]);\n",
    "sns.scatterplot(x=neg_x, y=neg_y, linewidth=0., alpha=.75, ax=ax[0]);\n",
    "\n",
    "ax[0].set_ylabel('No. of comments', **{'fontsize': 14})\n",
    "ax[0].set_xlabel('Score (negative)', **{'fontsize': 14})\n",
    "ax[1].set_ylabel('')\n",
    "ax[1].set_xlabel('Score (positive)', **{'fontsize': 14})\n",
    "\n",
    "ax[0].set_yscale('log')\n",
    "ax[1].set_yscale('log')\n",
    "\n",
    "ax[0].set_xscale('symlog')\n",
    "ax[1].set_xscale('symlog')\n",
    "\n",
    "ax[0].grid(True)\n",
    "ax[1].grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = comments_df.groupby('author').count().id.values\n",
    "k = Counter(dist)\n",
    "\n",
    "pl = powerlaw.Fit(dist, discrete=True, verbose=False)\n",
    "print(f'alpha = {pl.alpha}')\n",
    "print(f'∂ = {pl.D}')\n",
    "\n",
    "msg.info(\"No. of comments per n. of authors n:\")\n",
    "msg.info(f\"min: {min(dist)}, avg: {np.mean(dist)}, max: {max(dist)}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "sns.scatterplot(x=list(k.keys()), y=[k[x] for x in k.keys()], ax=ax, linewidth=0., alpha=.75);\n",
    "\n",
    "ax.set_ylabel('No. of comments', **{'fontsize': 14})\n",
    "ax.set_xlabel('No. of authors', **{'fontsize': 14})\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_flairs = ['cnjdg', 'cnlgd', 'cnsng', 'cntop', 'ruuol', 'eufnc', 'eug2', 'euml', 'eurogue', 'kodwg', 'kokdx', 'kogen', 'nafq', 'natl', 'natsm', 'twmad', 'cnpsg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_count = list()\n",
    "teams_authors = dict()\n",
    "\n",
    "for team_flair in teams_flairs:\n",
    "    mask = comments_df.cflairs.apply(lambda x, d=team_flair: d in map(lambda y: y.lower(), eval(x)))\n",
    "    teams_count.append((team_flair, len(comments_df[mask].author.unique())))\n",
    "    teams_authors[team_flair] = set(comments_df[mask].author.unique())\n",
    "\n",
    "teams_count = pd.DataFrame.from_records(teams_count, columns=['team', 'count'])\n",
    "print(\"Avg no. of authors supporting a team:\", teams_count['count'].mean(), teams_count['count'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_color_palette = (sns.color_palette()[0],) * 4 + (sns.color_palette()[3],) * 1 + (sns.color_palette()[1],) * 4 + (sns.color_palette()[6],) * 3 + (sns.color_palette()[-2],) * 3 + (sns.color_palette()[2],) * 1 + (sns.color_palette()[4],) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "sns.barplot(y='team', x='count', data=teams_count, orient='h', ax=ax, linewidth=0., alpha=1.0, palette=team_color_palette)\n",
    "ax.set_ylabel('Team', **{'fontsize': 14})\n",
    "ax.set_xlabel('No. of authors', **{'fontsize': 14})\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network-based Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ain_nodes = comments_df.author.unique()\n",
    "ain_edges = set()\n",
    "\n",
    "for record in comments_df.itertuples():\n",
    "    u = record.author\n",
    "    parent_type, parent_id = record.parent_id.split('_')\n",
    "    if parent_type == 't1':\n",
    "        comment_record = comments_df[comments_df.id == parent_id]\n",
    "        if len(comment_record) > 0:\n",
    "            v = comment_record['author'].values[0]\n",
    "            ain_edges.add((u,v))\n",
    "    else:\n",
    "        afs = threads_df[threads_df.id == parent_id]['author'].values[0]\n",
    "        ain_edges.add((u, afs))\n",
    "            \n",
    "ain_nodes_cmp = {u: np.mean(comments_df[comments_df.author == u].pol_cmp) for u in ain_nodes}\n",
    "ain_nodes_score = {u: np.mean(comments_df[comments_df.author == u].score) for u in ain_nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('nodes, edges, avg. indegree:', ain.number_of_nodes(), ain.number_of_edges(), sum(map(lambda x: x[1], ain.in_degree())) / ain.number_of_nodes(), sum(map(lambda x: x[1], ain.out_degree())) / ain.number_of_nodes())\n",
    "print('density:', nx.density(ain))\n",
    "print('clustering:', nx.average_clustering(ain))\n",
    "print('n. of s connected components:', len(list(nx.weakly_connected_components(ain))))\n",
    "print('size of the maximum s connected components:', len(max(nx.weakly_connected_components(ain), key=len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betw_cent = nx.algorithms.betweenness_centrality(ain, normalized=True)\n",
    "betw_cent_sorted = list(map(lambda u, d=betw_cent: (u, d[u]), sorted(betw_cent, key=lambda x: betw_cent[x], reverse=True)))[:20]\n",
    "eigen_cent = nx.algorithms.eigenvector_centrality(ain)\n",
    "eigen_cent_sorted = list(map(lambda u, d=eigen_cent: (u, d[u]), sorted(eigen_cent, key=lambda x: eigen_cent[x], reverse=True)))[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tin_nodes = teams_flairs\n",
    "tin_edges = list()\n",
    "\n",
    "for record in comments_df.itertuples():\n",
    "    tfs_i = eval(record.cflairs)\n",
    "    parent_type, parent_id = record.parent_id.split('_')\n",
    "    if parent_type == 't1':\n",
    "        comment_record = comments_df[comments_df.id == parent_id]\n",
    "        if len(comment_record) > 0:\n",
    "            tfs_j = eval(comment_record['cflairs'].values[0])\n",
    "            for ui in tfs_i:\n",
    "                for uj in tfs_i:\n",
    "                    if ui in teams_flairs and uj in teams_flairs:\n",
    "                        tin_edges.append((ui, uj))\n",
    "    else:\n",
    "        afs = [k['a'][1:-1] for k in eval(threads_df[threads_df.id == parent_id]['author_flair_richtext'].values[0]) if 'a' in k]\n",
    "        for ui in tfs_i:\n",
    "            for uj in afs:\n",
    "                if ui in teams_flairs and uj in teams_flairs:\n",
    "                    tin_edges.append((ui, uj))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = Counter(tin_edges)\n",
    "tin_edges_weight = [(k[0], k[1], freq[k])for k in list(freq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tin = nx.DiGraph()\n",
    "tin.add_nodes_from(tin_nodes)\n",
    "tin.add_weighted_edges_from(tin_edges_weight)\n",
    "\n",
    "nx.write_graphml(tin, 'tin.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('nodes, edges, avg. indegree:', tin.number_of_nodes(), tin.number_of_edges(), sum(map(lambda x: x[1], tin.in_degree())) / tin.number_of_nodes(), sum(map(lambda x: x[1], tin.out_degree())) / tin.number_of_nodes())\n",
    "print('density:', nx.density(tin))\n",
    "print('clustering:', nx.average_clustering(tin))\n",
    "print('n. of s connected components:', len(list(nx.weakly_connected_components(tin))))\n",
    "print('size of the maximum s connected components:', len(max(nx.weakly_connected_components(tin), key=len)))\n",
    "print('avg edge weight:', np.mean(list(map(lambda x: x[-1], tin_edges_weight))))\n",
    "print('std edge weight:', np.std(list(map(lambda x: x[-1], tin_edges_weight))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tin_df = pd.DataFrame.from_records(tin_edges_weight, columns=['t1', 't2', 'w'])\n",
    "tin_df_2 = tin_df.pivot(\"t1\", \"t2\", \"w\").fillna(0).astype('int32')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5.75))\n",
    "sns.heatmap(tin_df_2, annot=True, fmt='d', cmap=\"CMRmap_r\", linewidths=.5, color=\"#333333\", ax=ax, alpha=.75);\n",
    "\n",
    "ax.set_ylabel('', **{'fontsize': 14});\n",
    "ax.set_xlabel('', **{'fontsize': 14});\n",
    "\n",
    "ax.patch.set_edgecolor('black')\n",
    "ax.patch.set_linewidth('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_team = list()\n",
    "for record in comments_df.itertuples():\n",
    "    tfs_i = eval(record.cflairs)\n",
    "    for tf in tfs_i:\n",
    "        if tf in teams_flairs:\n",
    "            sent_team.append((tf, record.pol_cmp))\n",
    "\n",
    "sent_team_ordered = list()\n",
    "for tf in teams_flairs:\n",
    "    all_of_tf = list(filter(lambda x, t=tf: x[0] == t, sent_team))\n",
    "    sent_team_ordered += all_of_tf\n",
    "            \n",
    "sent_team = pd.DataFrame.from_records(sent_team_ordered, columns=['team', 'sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "sns.boxplot(data=sent_team, x='sentiment', y='team', width=0.525, palette='colorblind', linewidth=0.75, ax=ax);\n",
    "\n",
    "ax.set_xlim([-1.0, 1.0]);\n",
    "\n",
    "ax.set_ylabel('', **{'fontsize': 14});\n",
    "ax.set_xlabel('Sentiment value', **{'fontsize': 14});\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_team = list()\n",
    "for record in comments_df.itertuples():\n",
    "    tfs_i = eval(record.cflairs)\n",
    "    for tf in tfs_i:\n",
    "        if tf in teams_flairs:\n",
    "            score_team.append((tf, record.score))\n",
    "\n",
    "score_team_ordered = list()\n",
    "for tf in teams_flairs:\n",
    "    all_of_tf = list(filter(lambda x, t=tf: x[0] == t, score_team))\n",
    "    score_team_ordered += all_of_tf\n",
    "            \n",
    "score_team = pd.DataFrame.from_records(score_team_ordered, columns=['team', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "sns.stripplot(data=score_team, x='score', y='team', palette='colorblind', ax=ax);\n",
    "\n",
    "ax.set_ylabel('', **{'fontsize': 14});\n",
    "ax.set_xlabel('Comment score', **{'fontsize': 14});\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bp_analysis(tid_bp, flair_str):\n",
    "    bp = threads_df[threads_df.id == tid_bp].created.values[0]\n",
    "    before_bp_df = comments_df[(comments_df.cflairs.str.contains(flair_str)) & (comments_df.created < bp)]\n",
    "    after_bp_df = comments_df[(comments_df.cflairs.str.contains(flair_str)) & (comments_df.created >= bp)]\n",
    "    \n",
    "    msg.info(\"No. of comments before bp: {}\".format(len(before_bp_df)))\n",
    "    msg.info(\"No. of comments after bp: {}\".format(len(after_bp_df)))\n",
    "\n",
    "    msg.info(\"No. of distinct authors before bp: {}\".format(len(before_bp_df.author.unique())))\n",
    "    msg.info(\"No. of distinct authors before bp: {}\".format(len(after_bp_df.author.unique())))\n",
    "\n",
    "    overlapping_authors = set(before_bp_df.author.values).intersection(set(after_bp_df.author.values)) \n",
    "    msg.info(\"No. of authors overlapping between before and after: {}\".format(len(overlapping_authors)))\n",
    "\n",
    "    msg.info(\"Max, min and avg sentiment before: {} {} {} (± {})\".format(\n",
    "        before_bp_df.pol_cmp.max(),\n",
    "        before_bp_df.pol_cmp.min(),\n",
    "        before_bp_df.pol_cmp.mean(),\n",
    "        before_bp_df.pol_cmp.std()))\n",
    "    msg.info(\"Max, min and avg sentiment after: {} {} {} (± {})\".format(\n",
    "        after_bp_df.pol_cmp.max(),\n",
    "        after_bp_df.pol_cmp.min(),\n",
    "        after_bp_df.pol_cmp.mean(),\n",
    "        after_bp_df.pol_cmp.std()))\n",
    "    \n",
    "    msg.info(\"{} {}\".format(before_bp_df.score.mean(), before_bp_df.score.std()))\n",
    "    msg.info(\"{} {}\".format(after_bp_df.score.mean(), after_bp_df.score.std()))\n",
    "    \n",
    "    print(ranksums(before_bp_df.pol_cmp.values, after_bp_df.pol_cmp.values))\n",
    "    print(ranksums(before_bp_df.tb_pol.values, after_bp_df.tb_pol.values))\n",
    "    print(ranksums(before_bp_df.score.values, after_bp_df.score.values))\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(8,5))\n",
    "    sns.histplot(data=before_bp_df.pol_cmp.values, bins=30, ax=ax[0])\n",
    "    sns.histplot(data=after_bp_df.pol_cmp.values, bins=30, ax=ax[1])\n",
    "\n",
    "    return before_bp_df, after_bp_df, overlapping_authors\n",
    "\n",
    "def extract_bp_df(tid_bp='jct1io', flair_str='eufnc'):\n",
    "    bp = threads_df[threads_df.id == tid_bp].created.values[0]\n",
    "    before_bp_df = comments_df[(comments_df.cflairs.str.contains(flair_str)) & (comments_df.created < bp)]\n",
    "    after_bp_df = comments_df[(comments_df.cflairs.str.contains(flair_str)) & (comments_df.created >= bp)]\n",
    "    \n",
    "    return (before_bp_df, after_bp_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
